{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fashion_COND_DCGAN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Machine-Learning-Tokyo/Intro-to-GANs/blob/master/more_advanced/Fashion_COND_DCGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "14vb70Ys_sxa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Fashion Conditional DCGAN"
      ]
    },
    {
      "metadata": {
        "id": "KlRx5ymdZG0E",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Imports"
      ]
    },
    {
      "metadata": {
        "id": "tHZUZmOUNEoJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input, Dense, BatchNormalization, Reshape, Flatten\n",
        "from keras.layers import UpSampling2D, Conv2D\n",
        "from keras.layers import concatenate, Lambda\n",
        "import keras.backend as K\n",
        "from keras.utils import to_categorical\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.initializers import RandomNormal\n",
        "from keras.datasets import fashion_mnist\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uvvPV_WIZoR2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Function to build the generator"
      ]
    },
    {
      "metadata": {
        "id": "6gqJ4ZrmNHve",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def build_generator(noise_size, img_shape, num_classes):\n",
        "  \n",
        "  filters = 512\n",
        "  k_size = 5, 5\n",
        "  k_init = RandomNormal(0, 0.02)\n",
        "  \n",
        "  noise = Input((noise_size,))\n",
        "  label = Input((num_classes,))\n",
        "  model_input = concatenate([noise, label])\n",
        "  \n",
        "  x = Dense(4*4*filters, activation='relu', kernel_initializer=k_init)(model_input)\n",
        "  x = Reshape((4, 4, filters))(x)  # 4, 4\n",
        "  x = BatchNormalization()(x)\n",
        "  x = UpSampling2D()(x)  # 8, 8\n",
        "  \n",
        "  x = Conv2D(filters // 2, k_size, padding='same', activation='relu', kernel_initializer=k_init)(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = UpSampling2D()(x)  # 16, 16\n",
        "  \n",
        "  x = Conv2D(filters // 4, k_size, padding='same', activation='relu', kernel_initializer=k_init)(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = UpSampling2D()(x)  # 32, 32\n",
        "  \n",
        "  img = Conv2D(1, k_size, padding='same', activation='tanh', kernel_initializer=k_init)(x)\n",
        "  \n",
        "  generator = Model([noise, label], img)\n",
        "  return generator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ooEwRbP8eLgw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Function to build the discriminator"
      ]
    },
    {
      "metadata": {
        "id": "UysJTIlPOlZS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def build_discriminator(img_shape, num_classes):\n",
        "  \n",
        "  filters = 512\n",
        "  k_size = 5, 5\n",
        "  k_init = RandomNormal(0, 0.02)\n",
        "  \n",
        "  img = Input(img_shape)  # 32, 32\n",
        "  label = Input((num_classes,))\n",
        "  \n",
        "  emb_label = Reshape((1, 1, num_classes))(label)\n",
        "  emb_label = Lambda(lambda x: K.tile(x, (1, *img_shape[:2], 1)))(emb_label)\n",
        "  \n",
        "  model_input = concatenate([img, emb_label])\n",
        "  \n",
        "  x = Conv2D(filters // 4, k_size, strides=(2, 2), padding='same', kernel_initializer=k_init)(model_input)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = LeakyReLU(0.2)(x)  # 16, 16\n",
        "  \n",
        "  x = Conv2D(filters // 2, k_size, strides=(2, 2), padding='same', kernel_initializer=k_init)(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = LeakyReLU(0.2)(x)  # 8, 8\n",
        "  \n",
        "  x = Conv2D(filters, k_size, strides=(2, 2), padding='same', kernel_initializer=k_init)(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = LeakyReLU(0.2)(x)  # 4, 4\n",
        "  \n",
        "  x = Flatten()(x)\n",
        "  validity = Dense(1, activation='sigmoid')(x)\n",
        "  \n",
        "  discriminator = Model([img, label], validity)\n",
        "  return discriminator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uxDM6ldueOte",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Function to compile the models"
      ]
    },
    {
      "metadata": {
        "id": "gEfTuy93PRNb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_compiled_models(generator, discriminator, noise_size, num_classes):\n",
        "  \n",
        "  optimizer = Adam(0.0002, 0.5)\n",
        "  \n",
        "  discriminator.compile(optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "  discriminator.trainable = False\n",
        "  \n",
        "  noise = Input((noise_size,))\n",
        "  label = Input((num_classes,))\n",
        "  \n",
        "  img = generator([noise, label])\n",
        "  validity = discriminator([img, label])\n",
        "  combined = Model([noise, label], validity)\n",
        "  \n",
        "  combined.compile(optimizer, loss='binary_crossentropy')\n",
        "  \n",
        "  return generator, discriminator, combined"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ocu71YfmeSIH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Function to sample and save generated images"
      ]
    },
    {
      "metadata": {
        "id": "X4-ejg8UTwqV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def sample_imgs(generator, noise_size, step, plot_img=True, cond=False, num_classes=10):\n",
        "  np.random.seed(0)\n",
        "  \n",
        "  r, c = num_classes, 10\n",
        "  if cond:\n",
        "    noise = np.random.normal(0, 1, (c, noise_size))\n",
        "    noise = np.tile(noise, (r, 1))\n",
        "\n",
        "    sampled_labels = np.arange(r).reshape(-1, 1)\n",
        "    sampled_labels = to_categorical(sampled_labels, r)\n",
        "    sampled_labels = np.repeat(sampled_labels, c, axis=0)\n",
        "\n",
        "    imgs = generator.predict([noise, sampled_labels])\n",
        "  else:\n",
        "    noise = np.random.normal(0, 1, (r*c, noise_size))\n",
        "    imgs = generator.predict_on_batch(noise)\n",
        "  \n",
        "  imgs = imgs / 2 + 0.5\n",
        "  imgs = np.reshape(imgs, [r, c, imgs.shape[1], imgs.shape[2], -1])\n",
        "  \n",
        "  figsize = 1 * c, 1 * r\n",
        "  fig, axs = plt.subplots(r, c, figsize=figsize)\n",
        "  \n",
        "  for i in range(r):\n",
        "    for j in range(c):\n",
        "      img = imgs[i, j] if len(imgs.shape) == 4 else imgs[i, j, :, :, 0]\n",
        "      axs[i, j].imshow(img, cmap='gray')\n",
        "      axs[i, j].axis('off')\n",
        "  plt.subplots_adjust(wspace=0.1, hspace=0.1)\n",
        "  fig.savefig(f'/content/images/{step}.png')\n",
        "  if plot_img:\n",
        "    plt.show()\n",
        "  plt.close()\n",
        "  \n",
        "  np.random.seed(None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "K3ofIxpleVoc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Function to train the models"
      ]
    },
    {
      "metadata": {
        "id": "wHI7xwGMQRAW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train(models, noise_size, img_shape, num_classes, batch_size, steps):\n",
        "  \n",
        "  generator, discriminator, combined = models\n",
        "  #get real data\n",
        "  (X_train, Y_train), (X_val, Y_val) = fashion_mnist.load_data()\n",
        "  fashion_mnist_imgs = np.concatenate((X_train, X_val)) / 127.5 - 1\n",
        "  fashion_mnist_labels = np.concatenate((Y_train, Y_val))\n",
        "  fashion_mnist_imgs = np.pad(fashion_mnist_imgs, ((0, 0), (2, 2), (2, 2)), 'constant', constant_values=-1)\n",
        "  fashion_mnist_imgs = np.expand_dims(fashion_mnist_imgs, axis=-1)\n",
        "  \n",
        "  for step in range(1, steps + 1):\n",
        "    # train discriminator\n",
        "    inds = np.random.randint(0, fashion_mnist_imgs.shape[0], batch_size)\n",
        "    real_imgs = fashion_mnist_imgs[inds]\n",
        "    labels = fashion_mnist_labels[inds]\n",
        "    labels = to_categorical(labels, num_classes)\n",
        "    real_validity = np.ones(batch_size)\n",
        "    \n",
        "    noise = np.random.normal(0, 1, (batch_size, noise_size))\n",
        "    gen_imgs = generator.predict([noise, labels])\n",
        "    gen_validity = np.zeros(batch_size)\n",
        "    \n",
        "    r_loss = discriminator.train_on_batch([real_imgs, labels], real_validity)\n",
        "    g_loss = discriminator.train_on_batch([gen_imgs, labels], gen_validity)\n",
        "    disc_loss = np.add(r_loss, g_loss) / 2\n",
        "    \n",
        "    # train generator\n",
        "    noise = np.random.normal(0, 1, (batch_size, noise_size))\n",
        "    gen_validity = np.ones(batch_size)\n",
        "    gen_loss = combined.train_on_batch([noise, labels], gen_validity)\n",
        "    \n",
        "    #print progress\n",
        "    if step % 50 == 0:\n",
        "      print('step: %d, D_loss: %f, D_accuracy: %.2f%%, G_loss: %f' % (step, disc_loss[0],\n",
        "                                                                      disc_loss[1] * 100, gen_loss))\n",
        "    \n",
        "    # save_samples\n",
        "    if step % 200 == 0:\n",
        "      sample_imgs(generator, noise_size, step, cond=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jHnx_qUceZyc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Define hyperparameters"
      ]
    },
    {
      "metadata": {
        "id": "1-ePrmDUVBYM",
        "colab_type": "code",
        "outputId": "aeddb72e-fa64-44c5-afee-5089bddf95af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "%rm -r /content/images\n",
        "%mkdir /content/images\n",
        "noise_size = 100\n",
        "img_shape = 32, 32, 1\n",
        "num_classes = 10\n",
        "batch_size = 64\n",
        "steps = 10000"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove '/content/images': No such file or directory\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lhkkM5ctecbb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Generate the models"
      ]
    },
    {
      "metadata": {
        "id": "FCr5cDHOZCdW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "generator = build_generator(noise_size, img_shape, num_classes)\n",
        "discriminator = build_discriminator(img_shape, num_classes)\n",
        "compiled_models = get_compiled_models(generator, discriminator, noise_size, num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zTkuRejSefba",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Train the models"
      ]
    },
    {
      "metadata": {
        "id": "JznD-Lt6Y2h_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train(compiled_models, noise_size, img_shape, num_classes, batch_size, steps)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bzPwRKZzL4bV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Plot resutls"
      ]
    },
    {
      "metadata": {
        "id": "PS-SEYwnKHWY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install import_ipynb\n",
        "%cd /content\n",
        "%rm -r /content/0a16ae419d9eba160ddb4f48862fb9e2\n",
        "!git clone https://gist.github.com/dkatsios/0a16ae419d9eba160ddb4f48862fb9e2.git\n",
        "%cd /content/0a16ae419d9eba160ddb4f48862fb9e2\n",
        "import import_ipynb\n",
        "from IPython.display import HTML\n",
        "from AnimationDisplay import plot_results\n",
        "%cd /content"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qWjyh_s8WFG8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "path = '/content/images/{}.png'\n",
        "iterator = range(200, steps+1, 200)\n",
        "HTML(plot_results(path, iterator).to_jshtml())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GaDzs7MYQ3ah",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Download images and generator"
      ]
    },
    {
      "metadata": {
        "id": "mr9q_1QsQ60o",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "gen_path = '/content/gen.h5'\n",
        "generator.save(gen_path)\n",
        "from google.colab import files\n",
        "files.download(gen_path)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}